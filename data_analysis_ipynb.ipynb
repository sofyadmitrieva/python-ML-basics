{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofyadmitrieva/python-course/blob/main/data_analysis_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1: выгрузка файлов"
      ],
      "metadata": {
        "id": "aa2G_JERA7yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Зайдите в репозиторий датасетов для обучения диалоговых систем\n",
        "2. Найдите все файлы с расширением *.txt (их всего 5 в репозитории)\n",
        "3. Выгрузите каждый файл с помощью утилиты `wget`\n",
        "- Для этого откройте датасет в браузере, например, https://github.com/Phylliida/Dialogue-Datasets/blob/master/TwitterLowerAsciiCorpus.txt\n",
        "- Затем найдите кнопку `raw`, которая откроет вам файл \"как есть\" (как в блокноте!)\n",
        "- Скопируйте ссылку на файл (она выглядит так: https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt)\n",
        "- Воспользуйтесь `wget`\n",
        "---\n",
        "Как использовать `wget`:\n",
        "---"
      ],
      "metadata": {
        "id": "vrtdr5UF_TyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swBssiVj90wr",
        "outputId": "307311d9-90a6-40bf-b320-02067aa4e009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 18:13:34--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘twitter.txt’\n",
            "\n",
            "twitter.txt         100%[===================>] 579.79K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-12-05 18:13:34 (86.6 MB/s) - ‘twitter.txt’ saved [593707/593707]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O twitter.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь:\n",
        "- ! указывает на то, что это консольная утилита, а не код на python\n",
        "- после wget идет полный адрес ссылки для скачивания файла\n",
        "- после параметра `-O` указываем название файла, под которым мы хотим скачать файл"
      ],
      "metadata": {
        "id": "kekDrEGyAXUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь: повторите процедуру для остальных файлов (всего должно быть 5 файлов)"
      ],
      "metadata": {
        "id": "1FAveoWrAWm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt -O TwitterConvCorpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cxjujywvLcn",
        "outputId": "43e90b83-9dce-4afa-f939-5b433ed8b32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 18:20:58--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 612338 (598K) [text/plain]\n",
            "Saving to: ‘TwitterConvCorpus.txt’\n",
            "\n",
            "\rTwitterConvCorpus.t   0%[                    ]       0  --.-KB/s               \rTwitterConvCorpus.t 100%[===================>] 597.99K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-12-05 18:20:58 (98.4 MB/s) - ‘TwitterConvCorpus.txt’ saved [612338/612338]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O TwitterLowerAsciiCorpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZC_mqnavX0A",
        "outputId": "6c04c363-eecc-4757-f127-f63d35d8b24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 18:21:41--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘TwitterLowerAsciiCorpus.txt’\n",
            "\n",
            "TwitterLowerAsciiCo 100%[===================>] 579.79K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2025-12-05 18:21:41 (115 MB/s) - ‘TwitterLowerAsciiCorpus.txt’ saved [593707/593707]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt -O MovieCorpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rze-oxgcv6_b",
        "outputId": "b908d824-1f0c-4277-dc27-6c2a96af9f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 18:22:42--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16976724 (16M) [text/plain]\n",
            "Saving to: ‘MovieCorpus.txt’\n",
            "\n",
            "MovieCorpus.txt     100%[===================>]  16.19M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-12-05 18:22:43 (304 MB/s) - ‘MovieCorpus.txt’ saved [16976724/16976724]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt -O BNCSplitWordsCorpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "misNlfdswJgp",
        "outputId": "d8c83c9a-03d0-4f90-bcba-c7fef99ba29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 18:23:51--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19173003 (18M) [text/plain]\n",
            "Saving to: ‘BNCSplitWordsCorpus.txt’\n",
            "\n",
            "BNCSplitWordsCorpus 100%[===================>]  18.28M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-12-05 18:23:52 (336 MB/s) - ‘BNCSplitWordsCorpus.txt’ saved [19173003/19173003]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt -O BNCCorpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpGZ4djJwcu6",
        "outputId": "f133ed55-c868-43ad-bf2b-44116400fa1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 18:24:48--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19081694 (18M) [text/plain]\n",
            "Saving to: ‘BNCCorpus.txt’\n",
            "\n",
            "BNCCorpus.txt       100%[===================>]  18.20M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-12-05 18:24:50 (316 MB/s) - ‘BNCCorpus.txt’ saved [19081694/19081694]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2: открываем файлы"
      ],
      "metadata": {
        "id": "JLaq0LFXBBI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изучите туториал по работе с файлами, который вы получили в чате. Каждый файл нужно теперь открыть, а его содержание - записать в переменную *любым удобным вам способом*\n",
        "\n",
        "Пример:"
      ],
      "metadata": {
        "id": "AjNtW5R1BI7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('twitter.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "_uJqiGUpBFEV",
        "outputId": "4f67d0c4-6c76-4c84-ba91-f1152249fc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь: откройте все файлы, выведите на экран их размер и первые 100 символов (всего должно быть обработано 5 файлов)"
      ],
      "metadata": {
        "id": "yrYxdTj6BGv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('TwitterConvCorpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "GP9BAoD5w0Xn",
        "outputId": "40be30de-7045-4cd3-93eb-ac48eef4419b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 598556 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on Twitter? Haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('TwitterLowerAsciiCorpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "caIDZ9s-w9V2",
        "outputId": "81d2217d-e73a-40b0-ef86-fc7612b409fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('MovieCorpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "jAcLDQC6w9kP",
        "outputId": "ef90c447-6188-4be8-f927-8a5cec2274fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 16976724 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Colonel Durnford... William Vereker. I hear you 've been seeking Officers?\\nGood ones, yes, Mr Vereke\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('BNCSplitWordsCorpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "8p1LutrNw90n",
        "outputId": "e19cf715-25ee-4153-b7ea-9a1b15cac32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 19173003 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You enjoyed yourself in America\\nEh\\ndid you\\nOh I covered a nice trip yes\\nOh very good\\nsaw Mary and An'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('BNCCorpus.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "PgUQqGAqw9_m",
        "outputId": "ca6a2d0e-7046-4e10-f3ec-e9202a5761f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 19081694 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You enjoyed yourself in America\\nEh\\ndid you\\nOh I covered a nice tripyes\\nOh very good\\nsaw Mary and And'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 3: первичный анализ"
      ],
      "metadata": {
        "id": "vSc5RUhgBu_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем статистику для каждого файла по образцу:"
      ],
      "metadata": {
        "id": "ui-vA_4wB76-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = 0         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words_before}\")\n",
        "print(f\"Всего символов: {total_chars_before}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XliSd4K4Byym",
        "outputId": "77a6fdad-c1c4-4baa-a8d6-0a6cceb61d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16557\n",
            "Непустых строк: 10514\n",
            "Всего слов: 112977\n",
            "Всего символов: 577151\n",
            "Макс. длина строки: 146\n",
            "Мин. длина строки: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open(\"TwitterConvCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = 0         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_lines += 1\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "\n",
        "    total_chars += len(clean_line)\n",
        "    words = clean_line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "    if len(clean_line) > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   #  максимальная длина строки\n",
        "min_line_length = None   # минимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "    length = len(clean_line)\n",
        "\n",
        "    # обновляем максимум\n",
        "    if length > max_line_length:\n",
        "        max_line_length = length\n",
        "\n",
        "    # обновляем минимум\n",
        "    if min_line_length is None or length < min_line_length:\n",
        "        min_line_length = length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75972330-0080-4619-a46b-148f0d320efa",
        "id": "YF4lMyTbzPnx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16556\n",
            "Непустых строк: 10628\n",
            "Всего слов: 114910\n",
            "Всего символов: 582000\n",
            "Макс. длина строки: 146\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open(\"TwitterLowerAsciiCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = 0         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_lines += 1\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "\n",
        "    total_chars += len(clean_line)\n",
        "    words = clean_line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "    if len(clean_line) > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   #  максимальная длина строки\n",
        "min_line_length = None   # минимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "    length = len(clean_line)\n",
        "\n",
        "    # обновляем максимум\n",
        "    if length > max_line_length:\n",
        "        max_line_length = length\n",
        "\n",
        "    # обновляем минимум\n",
        "    if min_line_length is None or length < min_line_length:\n",
        "        min_line_length = length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc93a33d-7af4-43d7-9abb-76a990994e8c",
        "id": "NtxvEldGGeob"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16556\n",
            "Непустых строк: 10514\n",
            "Всего слов: 112977\n",
            "Всего символов: 577151\n",
            "Макс. длина строки: 146\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open(\"MovieCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = 0         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_lines += 1\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "\n",
        "    total_chars += len(clean_line)\n",
        "    words = clean_line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "    if len(clean_line) > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   #  максимальная длина строки\n",
        "min_line_length = None   # минимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "    length = len(clean_line)\n",
        "\n",
        "    # обновляем максимум\n",
        "    if length > max_line_length:\n",
        "        max_line_length = length\n",
        "\n",
        "    # обновляем минимум\n",
        "    if min_line_length is None or length < min_line_length:\n",
        "        min_line_length = length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aebde80-2e70-4849-e9e7-903da5618c1a",
        "id": "xzzcyGDGGma7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 304713\n",
            "Непустых строк: 304713\n",
            "Всего слов: 3185395\n",
            "Всего символов: 16672011\n",
            "Макс. длина строки: 3039\n",
            "Мин. длина строки: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open(\"BNCSplitWordsCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = 0         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_lines += 1\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "\n",
        "    total_chars += len(clean_line)\n",
        "    words = clean_line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "    if len(clean_line) > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   #  максимальная длина строки\n",
        "min_line_length = None   # минимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "    length = len(clean_line)\n",
        "\n",
        "    # обновляем максимум\n",
        "    if length > max_line_length:\n",
        "        max_line_length = length\n",
        "\n",
        "    # обновляем минимум\n",
        "    if min_line_length is None or length < min_line_length:\n",
        "        min_line_length = length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d9822a-7ddb-4cd4-cf31-40b15f8db08b",
        "id": "L0PMkC_eGyul"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 611014\n",
            "Непустых строк: 606486\n",
            "Всего слов: 4052241\n",
            "Всего символов: 18561989\n",
            "Макс. длина строки: 2773\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "# Ваш код здесь\n",
        "with open(\"BNCCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  all_lines = file.readlines()\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = 0         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    total_lines += 1\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "\n",
        "    total_chars += len(clean_line)\n",
        "    words = clean_line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "    if len(clean_line) > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "# 3. Анализ длин строк\n",
        "max_line_length = 0   #  максимальная длина строки\n",
        "min_line_length = None   # минимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "for line in all_lines:\n",
        "    clean_line = line.rstrip(\"\\n\")\n",
        "    length = len(clean_line)\n",
        "\n",
        "    # обновляем максимум\n",
        "    if length > max_line_length:\n",
        "        max_line_length = length\n",
        "\n",
        "    # обновляем минимум\n",
        "    if min_line_length is None or length < min_line_length:\n",
        "        min_line_length = length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c248623-fc8e-4c5f-8b8b-78c9383163c7",
        "id": "UKWFYZmeG3br"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 611014\n",
            "Непустых строк: 606486\n",
            "Всего слов: 3719853\n",
            "Всего символов: 18470680\n",
            "Макс. длина строки: 2702\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4: чистка текста"
      ],
      "metadata": {
        "id": "aptZI3yhEOlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words1 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "# 3. Убираем лишние пробелы\n",
        "# 4. Приводим к нижнему регистру\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "with open(\"TwitterConvCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "for line in all_lines:\n",
        "    clean = line.strip()\n",
        "    clean = re.sub(r\"[^a-zA-Zа-яА-Я0-9 ]\", \" \", clean)\n",
        "    clean = re.sub(r\"\\s+\", \" \", clean)\n",
        "    clean = clean.lower()\n",
        "    words = [w for w in clean.split() if len(w) > 1]\n",
        "    all_cleaned_words1.extend(words)\n",
        "    cleaned_lines.append(clean)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDEshS1DMo4",
        "outputId": "c69e06a2-650c-48e0-94e2-edc8115261c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: what s up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 104982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words2 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "# 3. Убираем лишние пробелы\n",
        "# 4. Приводим к нижнему регистру\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "with open(\"TwitterLowerAsciiCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "for line in all_lines:\n",
        "    clean = line.strip()\n",
        "    clean = re.sub(r\"[^a-zA-Zа-яА-Я0-9 ]\", \" \", clean)\n",
        "    clean = re.sub(r\"\\s+\", \" \", clean)\n",
        "    clean = clean.lower()\n",
        "    words = [w for w in clean.split() if len(w) > 1]\n",
        "    all_cleaned_words2.extend(words)\n",
        "    cleaned_lines.append(clean)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15218ae5-7be8-4dcc-b0d5-90125dec929e",
        "id": "iXIVsA4ALxch"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: what s up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 104967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words3 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "# 3. Убираем лишние пробелы\n",
        "# 4. Приводим к нижнему регистру\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "with open(\"MovieCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "for line in all_lines:\n",
        "    clean = line.strip()\n",
        "    clean = re.sub(r\"[^a-zA-Zа-яА-Я0-9 ]\", \" \", clean)\n",
        "    clean = re.sub(r\"\\s+\", \" \", clean)\n",
        "    clean = clean.lower()\n",
        "    words = [w for w in clean.split() if len(w) > 1]\n",
        "    all_cleaned_words3.extend(words)\n",
        "    cleaned_lines.append(clean)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e618d0c-2034-4b46-a222-c08ce8346b3c",
        "id": "EmEJNvENL5Wt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: colonel durnford william vereker i hear you ve been seeking officers ...\n",
            "Всего очищенных слов: 3016552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words4 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "# 3. Убираем лишние пробелы\n",
        "# 4. Приводим к нижнему регистру\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "with open(\"BNCSplitWordsCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "for line in all_lines:\n",
        "    clean = line.strip()\n",
        "    clean = re.sub(r\"[^a-zA-Zа-яА-Я0-9 ]\", \" \", clean)\n",
        "    clean = re.sub(r\"\\s+\", \" \", clean)\n",
        "    clean = clean.lower()\n",
        "    words = [w for w in clean.split() if len(w) > 1]\n",
        "    all_cleaned_words4.extend(words)\n",
        "    cleaned_lines.append(clean)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0807ac90-06e1-4034-fe7c-362a30fde9fd",
        "id": "AVvL_LN7MDyH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 3779461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words5 = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "# Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "# 1. Используйте strip для удаления лишних пробелов из строки\n",
        "# 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "# 3. Убираем лишние пробелы\n",
        "# 4. Приводим к нижнему регистру\n",
        "# 5. Собираем все слова после очистки в единый список\n",
        "#    - не фиксируем слова короче 1 символа\n",
        "with open(\"BNCCorpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    all_lines = file.readlines()\n",
        "\n",
        "for line in all_lines:\n",
        "    clean = line.strip()\n",
        "    clean = re.sub(r\"[^a-zA-Zа-яА-Я0-9 ]\", \" \", clean)\n",
        "    clean = re.sub(r\"\\s+\", \" \", clean)\n",
        "    clean = clean.lower()\n",
        "    words = [w for w in clean.split() if len(w) > 1]\n",
        "    all_cleaned_words5.extend(words)\n",
        "    cleaned_lines.append(clean)\n",
        "\n",
        "# Выводим результат для каждого текста по образцу\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ba96a6-0e2d-40b9-b96f-58357bcbf9ee",
        "id": "EjA7T3HOMMPZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 3563963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 5: статистика"
      ],
      "metadata": {
        "id": "WvPQoLBzGvAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 1: получаем статистику распределений длин слов"
      ],
      "metadata": {
        "id": "Iirxb-yneJqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words1 = len(all_cleaned_words1)\n",
        "total_chars1 = 0\n",
        "word_lengths1 = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "# и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words1:\n",
        "    length = len(word)\n",
        "    word_lengths1.append(length)\n",
        "    total_chars1 += length\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count1 = {}\n",
        "for length in word_lengths1:\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "# если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "    if length in word_length_count1:\n",
        "        word_length_count1[length] += 1\n",
        "#                иначе: выполняем >\n",
        "    else:\n",
        "        word_length_count1[length] = 1\n",
        "\n",
        "total_words_after = total_words1\n",
        "total_chars_after = total_chars1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words_after}\")\n",
        "print(f\"Символов после очистки: {total_chars_after}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count1.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count1[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Z1tTq5DQFA",
        "outputId": "f04b37f1-535b-47c7-f114-3c162dbc7ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 104982\n",
            "Символов после очистки: 438140\n",
            "Распределение длин слов:\n",
            "  2 букв: 20469 слов\n",
            "  3 букв: 25367 слов\n",
            "  4 букв: 25116 слов\n",
            "  5 букв: 12793 слов\n",
            "  6 букв: 7751 слов\n",
            "  7 букв: 5997 слов\n",
            "  8 букв: 3435 слов\n",
            "  9 букв: 2022 слов\n",
            "  10 букв: 1058 слов\n",
            "  11 букв: 490 слов\n",
            "  12 букв: 238 слов\n",
            "  13 букв: 118 слов\n",
            "  14 букв: 50 слов\n",
            "  15 букв: 26 слов\n",
            "  16 букв: 17 слов\n",
            "  17 букв: 10 слов\n",
            "  18 букв: 5 слов\n",
            "  19 букв: 5 слов\n",
            "  20 букв: 5 слов\n",
            "  21 букв: 1 слов\n",
            "  22 букв: 2 слов\n",
            "  23 букв: 2 слов\n",
            "  24 букв: 1 слов\n",
            "  25 букв: 1 слов\n",
            "  33 букв: 1 слов\n",
            "  41 букв: 1 слов\n",
            "  98 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words2 = len(all_cleaned_words2)\n",
        "total_chars2 = 0\n",
        "word_lengths2 = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "# и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words2:\n",
        "    length = len(word)\n",
        "    word_lengths2.append(length)\n",
        "    total_chars2 += length\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count2 = {}\n",
        "for length in word_lengths2:\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "# если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "    if length in word_length_count2:\n",
        "        word_length_count2[length] += 1\n",
        "#                иначе: выполняем >\n",
        "    else:\n",
        "        word_length_count2[length] = 1\n",
        "\n",
        "total_words_after = total_words2\n",
        "total_chars_after = total_chars2\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words_after}\")\n",
        "print(f\"Символов после очистки: {total_chars_after}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count2.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count2[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ac5a79-fc8d-4e01-af01-96dea0fd67b0",
        "id": "PK_iKJOqO-SP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 104967\n",
            "Символов после очистки: 438282\n",
            "Распределение длин слов:\n",
            "  2 букв: 20430 слов\n",
            "  3 букв: 25349 слов\n",
            "  4 букв: 25124 слов\n",
            "  5 букв: 12802 слов\n",
            "  6 букв: 7759 слов\n",
            "  7 букв: 6005 слов\n",
            "  8 букв: 3435 слов\n",
            "  9 букв: 2024 слов\n",
            "  10 букв: 1063 слов\n",
            "  11 букв: 491 слов\n",
            "  12 букв: 238 слов\n",
            "  13 букв: 118 слов\n",
            "  14 букв: 51 слов\n",
            "  15 букв: 26 слов\n",
            "  16 букв: 17 слов\n",
            "  17 букв: 10 слов\n",
            "  18 букв: 5 слов\n",
            "  19 букв: 5 слов\n",
            "  20 букв: 5 слов\n",
            "  21 букв: 1 слов\n",
            "  22 букв: 2 слов\n",
            "  23 букв: 2 слов\n",
            "  24 букв: 1 слов\n",
            "  25 букв: 1 слов\n",
            "  33 букв: 1 слов\n",
            "  41 букв: 1 слов\n",
            "  98 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words3 = len(all_cleaned_words3)\n",
        "total_chars3 = 0\n",
        "word_lengths3 = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "# и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words3:\n",
        "    length = len(word)\n",
        "    word_lengths3.append(length)\n",
        "    total_chars3 += length\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count3 = {}\n",
        "for length in word_lengths3:\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "# если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "    if length in word_length_count3:\n",
        "        word_length_count3[length] += 1\n",
        "#                иначе: выполняем >\n",
        "    else:\n",
        "        word_length_count3[length] = 1\n",
        "\n",
        "total_words_after = total_words3\n",
        "total_chars_after = total_chars3\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words_after}\")\n",
        "print(f\"Символов после очистки: {total_chars_after}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count3.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count3[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08fafd3-7092-4dc7-cf2f-da62fd98d227",
        "id": "HKXxksK0PcVu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3016552\n",
            "Символов после очистки: 12311380\n",
            "Распределение длин слов:\n",
            "  2 букв: 608359 слов\n",
            "  3 букв: 768275 слов\n",
            "  4 букв: 724231 слов\n",
            "  5 букв: 354812 слов\n",
            "  6 букв: 210450 слов\n",
            "  7 букв: 155903 слов\n",
            "  8 букв: 86905 слов\n",
            "  9 букв: 53298 слов\n",
            "  10 букв: 29783 слов\n",
            "  11 букв: 12716 слов\n",
            "  12 букв: 6420 слов\n",
            "  13 букв: 3116 слов\n",
            "  14 букв: 1229 слов\n",
            "  15 букв: 513 слов\n",
            "  16 букв: 255 слов\n",
            "  17 букв: 101 слов\n",
            "  18 букв: 56 слов\n",
            "  19 букв: 34 слов\n",
            "  20 букв: 19 слов\n",
            "  21 букв: 16 слов\n",
            "  22 букв: 7 слов\n",
            "  23 букв: 15 слов\n",
            "  24 букв: 11 слов\n",
            "  25 букв: 6 слов\n",
            "  27 букв: 6 слов\n",
            "  29 букв: 4 слов\n",
            "  30 букв: 4 слов\n",
            "  33 букв: 2 слов\n",
            "  34 букв: 2 слов\n",
            "  35 букв: 3 слов\n",
            "  38 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words4 = len(all_cleaned_words4)\n",
        "total_chars4 = 0\n",
        "word_lengths4 = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "# и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words4:\n",
        "    length = len(word)\n",
        "    word_lengths4.append(length)\n",
        "    total_chars4 += length\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count4 = {}\n",
        "for length in word_lengths4:\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "# если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "    if length in word_length_count4:\n",
        "        word_length_count4[length] += 1\n",
        "#                иначе: выполняем >\n",
        "    else:\n",
        "        word_length_count4[length] = 1\n",
        "\n",
        "total_words_after = total_words4\n",
        "total_chars_after = total_chars4\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words_after}\")\n",
        "print(f\"Символов после очистки: {total_chars_after}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count4.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count4[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072f57e6-f4e4-4ae7-b335-7788428df9a8",
        "id": "raGmDAyTQhBp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3779461\n",
            "Символов после очистки: 14298798\n",
            "Распределение длин слов:\n",
            "  2 букв: 895259 слов\n",
            "  3 букв: 1001636 слов\n",
            "  4 букв: 971266 слов\n",
            "  5 букв: 405070 слов\n",
            "  6 букв: 214880 слов\n",
            "  7 букв: 145574 слов\n",
            "  8 букв: 75104 слов\n",
            "  9 букв: 41706 слов\n",
            "  10 букв: 18583 слов\n",
            "  11 букв: 5763 слов\n",
            "  12 букв: 2844 слов\n",
            "  13 букв: 1133 слов\n",
            "  14 букв: 282 слов\n",
            "  15 букв: 52 слов\n",
            "  16 букв: 19 слов\n",
            "  17 букв: 63 слов\n",
            "  18 букв: 22 слов\n",
            "  19 букв: 205 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Статистика по очищенным данным\n",
        "total_words5 = len(all_cleaned_words5)\n",
        "total_chars5 = 0\n",
        "word_lengths5 = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "# и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words5:\n",
        "    length = len(word)\n",
        "    word_lengths5.append(length)\n",
        "    total_chars5 += length\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count5 = {}\n",
        "for length in word_lengths5:\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "# если длина уже зафиксирована в word_length_count, то выполняем >\n",
        "    if length in word_length_count5:\n",
        "        word_length_count5[length] += 1\n",
        "#                иначе: выполняем >\n",
        "    else:\n",
        "        word_length_count5[length] = 1\n",
        "\n",
        "total_words_after = total_words5\n",
        "total_chars_after = total_chars5\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words_after}\")\n",
        "print(f\"Символов после очистки: {total_chars_after}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count5.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count5[length]} слов\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38322aac-737a-4768-eb72-a02e9b6ce7ed",
        "id": "Rtq4h0__Qgtm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3563963\n",
            "Символов после очистки: 14406275\n",
            "Распределение длин слов:\n",
            "  2 букв: 765022 слов\n",
            "  3 букв: 903273 слов\n",
            "  4 букв: 873122 слов\n",
            "  5 букв: 393326 слов\n",
            "  6 букв: 232199 слов\n",
            "  7 букв: 168105 слов\n",
            "  8 букв: 100319 слов\n",
            "  9 букв: 57975 слов\n",
            "  10 букв: 32093 слов\n",
            "  11 букв: 15438 слов\n",
            "  12 букв: 9550 слов\n",
            "  13 букв: 5120 слов\n",
            "  14 букв: 2978 слов\n",
            "  15 букв: 1758 слов\n",
            "  16 букв: 1117 слов\n",
            "  17 букв: 608 слов\n",
            "  18 букв: 504 слов\n",
            "  19 букв: 295 слов\n",
            "  20 букв: 239 слов\n",
            "  21 букв: 155 слов\n",
            "  22 букв: 154 слов\n",
            "  23 букв: 95 слов\n",
            "  24 букв: 89 слов\n",
            "  25 букв: 52 слов\n",
            "  26 букв: 45 слов\n",
            "  27 букв: 53 слов\n",
            "  28 букв: 33 слов\n",
            "  29 букв: 25 слов\n",
            "  30 букв: 27 слов\n",
            "  31 букв: 11 слов\n",
            "  32 букв: 33 слов\n",
            "  33 букв: 17 слов\n",
            "  34 букв: 14 слов\n",
            "  35 букв: 16 слов\n",
            "  36 букв: 16 слов\n",
            "  37 букв: 4 слов\n",
            "  38 букв: 2 слов\n",
            "  39 букв: 18 слов\n",
            "  40 букв: 2 слов\n",
            "  41 букв: 3 слов\n",
            "  42 букв: 5 слов\n",
            "  43 букв: 2 слов\n",
            "  44 букв: 3 слов\n",
            "  45 букв: 7 слов\n",
            "  47 букв: 3 слов\n",
            "  48 букв: 4 слов\n",
            "  49 букв: 1 слов\n",
            "  51 букв: 2 слов\n",
            "  52 букв: 1 слов\n",
            "  53 букв: 1 слов\n",
            "  56 букв: 2 слов\n",
            "  57 букв: 1 слов\n",
            "  58 букв: 1 слов\n",
            "  59 букв: 5 слов\n",
            "  60 букв: 7 слов\n",
            "  63 букв: 1 слов\n",
            "  65 букв: 4 слов\n",
            "  66 букв: 1 слов\n",
            "  87 букв: 1 слов\n",
            "  90 букв: 1 слов\n",
            "  104 букв: 1 слов\n",
            "  105 букв: 2 слов\n",
            "  112 букв: 1 слов\n",
            "  114 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 2: частотность слов"
      ],
      "metadata": {
        "id": "gFZj9nmSeSGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency1 = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "for word in all_cleaned_words1:\n",
        "    if word in word_frequency1:\n",
        "      word_frequency1[word] += 1\n",
        "    else:\n",
        "      word_frequency1[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs1 = []\n",
        "for word, count in word_frequency1.items():\n",
        "    word_count_pairs1.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs1)):\n",
        "    for j in range(i + 1, len(word_count_pairs1)):\n",
        "        if word_count_pairs1[j][0] > word_count_pairs1[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs1[i]\n",
        "            word_count_pairs1[i] = word_count_pairs1[j]\n",
        "            word_count_pairs1[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs1))):\n",
        "    count, word = word_count_pairs1[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words1 = set(all_cleaned_words1)\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12uZ3UlLDSJv",
        "outputId": "35034b77-4099-4fa6-9143-ea9547e8f33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-10 самых частых слов:\n",
            "  1. 'the': 2928 раз\n",
            "  2. 'to': 2579 раз\n",
            "  3. 'you': 2575 раз\n",
            "  4. 'it': 2094 раз\n",
            "  5. 'and': 1669 раз\n",
            "  6. 'that': 1456 раз\n",
            "  7. 'my': 1201 раз\n",
            "  8. 'in': 1174 раз\n",
            "  9. 'is': 1096 раз\n",
            "  10. 'of': 1085 раз\n",
            "\n",
            "Всего уникальных слов: 10742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency2 = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "for word in all_cleaned_words2:\n",
        "    if word in word_frequency2:\n",
        "      word_frequency2[word] += 1\n",
        "    else:\n",
        "      word_frequency2[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs2 = []\n",
        "for word, count in word_frequency2.items():\n",
        "    word_count_pairs2.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs2)):\n",
        "    for j in range(i + 1, len(word_count_pairs2)):\n",
        "        if word_count_pairs2[j][0] > word_count_pairs2[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs2[i]\n",
        "            word_count_pairs2[i] = word_count_pairs2[j]\n",
        "            word_count_pairs2[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs2))):\n",
        "    count, word = word_count_pairs2[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words2 = set(all_cleaned_words2)\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a6dc30-a752-495b-b54f-a02729c7d6ca",
        "id": "o9C_m16CUxkN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-10 самых частых слов:\n",
            "  1. 'the': 2928 раз\n",
            "  2. 'to': 2579 раз\n",
            "  3. 'you': 2564 раз\n",
            "  4. 'it': 2075 раз\n",
            "  5. 'and': 1668 раз\n",
            "  6. 'that': 1450 раз\n",
            "  7. 'my': 1201 раз\n",
            "  8. 'in': 1174 раз\n",
            "  9. 'is': 1096 раз\n",
            "  10. 'of': 1084 раз\n",
            "\n",
            "Всего уникальных слов: 10765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency3 = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "for word in all_cleaned_words3:\n",
        "    if word in word_frequency3:\n",
        "      word_frequency3[word] += 1\n",
        "    else:\n",
        "      word_frequency3[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs3 = []\n",
        "for word, count in word_frequency3.items():\n",
        "    word_count_pairs3.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs3)):\n",
        "    for j in range(i + 1, len(word_count_pairs3)):\n",
        "        if word_count_pairs3[j][0] > word_count_pairs3[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs3[i]\n",
        "            word_count_pairs3[i] = word_count_pairs3[j]\n",
        "            word_count_pairs3[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs3))):\n",
        "    count, word = word_count_pairs3[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words3 = set(all_cleaned_words3)\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words3)}\")"
      ],
      "metadata": {
        "id": "xUrVFpOtUyf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency4 = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "for word in all_cleaned_words4:\n",
        "    if word in word_frequency4:\n",
        "      word_frequency4[word] += 1\n",
        "    else:\n",
        "      word_frequency4[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs4 = []\n",
        "for word, count in word_frequency4.items():\n",
        "    word_count_pairs4.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs4)):\n",
        "    for j in range(i + 1, len(word_count_pairs4)):\n",
        "        if word_count_pairs4[j][0] > word_count_pairs4[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs4[i]\n",
        "            word_count_pairs4[i] = word_count_pairs4[j]\n",
        "            word_count_pairs4[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs4))):\n",
        "    count, word = word_count_pairs4[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words4 = set(all_cleaned_words4)\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words4)}\")"
      ],
      "metadata": {
        "id": "mqQ9aL4TUy0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency5 = {}\n",
        "# Ваш код здесь:\n",
        "# проходим по all_cleaned_words\n",
        "# если слово зафиксировано в word_frequency, то\n",
        "for word in all_cleaned_words5:\n",
        "    if word in word_frequency5:\n",
        "      word_frequency5[word] += 1\n",
        "    else:\n",
        "      word_frequency5[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs5 = []\n",
        "for word, count in word_frequency5.items():\n",
        "    word_count_pairs5.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs5)):\n",
        "    for j in range(i + 1, len(word_count_pairs5)):\n",
        "        if word_count_pairs5[j][0] > word_count_pairs5[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs5[i]\n",
        "            word_count_pairs5[i] = word_count_pairs5[j]\n",
        "            word_count_pairs5[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs5))):\n",
        "    count, word = word_count_pairs5[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words5 = set(all_cleaned_words5)\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words5)}\")"
      ],
      "metadata": {
        "id": "A_Hodn1GUzAk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}